# Grouped Relative Policy Optimization (GRPO)
# ./apps/grpo/slurm/submit.sh qwen3_8b

# Global configuration
group_size: 16
local_batch_size: 1
max_req_tokens: 1024
max_res_tokens: 2048
model: "Qwen/Qwen3-8B"
off_by_n: 1
compile: true

provisioner:
  launcher: slurm
  job_name: grpo_qwen3_8b
  slurm_args:
    account: AIFAC_L07_016
    qos: qos_llm_min
    partition: boost_usr_prod
  mem: 0
  cpus_per_task: 32
  gpus_per_node: 4

metric_logging:
  wandb:
    entity: torchforge
    project: grpo-training
    group: grpo_exp_${oc.env:USER}
    logging_mode: global_reduce
  console:
    logging_mode: global_reduce

dataset:
  path: "/leonardo_scratch/fast/iGen_train/dsalvati/forge/gsm8k"
  revision: "main"
  data_split: "train"
  streaming: true
  model: ${model}

generator:
  engine_args:
    model: ${model}
    tensor_parallel_size: 4
    pipeline_parallel_size: 1
    enforce_eager: ${not:${compile}}
  sampling_params:
    n: ${group_size}
    max_tokens: ${max_res_tokens}
    temperature: 1.0
    top_p: 1.0

trainer:
  model:
    name: qwen3
    flavor: 8B
    hf_assets_path: hf://${model}
  optimizer:
    name: AdamW
    lr: 1e-5
    eps: 1e-8
  lr_scheduler:
    warmup_steps: 1
  training:
    local_batch_size: ${local_batch_size}
    seq_len: ${sum:${max_req_tokens},${max_res_tokens}}
    max_norm: 1.0
    steps: 1000000
    dtype: bfloat16
    gc_freq: 1
  compile:
    enable: ${compile}
  parallelism:
    data_parallel_replicate_degree: 1
    data_parallel_shard_degree: 1
    tensor_parallel_degree: 4
    pipeline_parallel_degree: 1
    context_parallel_degree: 1
    expert_parallel_degree: 1
    disable_loss_parallel: true
  checkpoint:
    enable: true
    folder: ./checkpoint
    initial_load_path: hf://${model}
    initial_load_in_hf: true
    last_save_in_hf: true
    interval: 500
    async_mode: "disabled"
  activation_checkpoint:
    mode: selective
    selective_ac_option: op
  comm:
    init_timeout_seconds: 1800

replay_buffer:
  batch_size: ${local_batch_size}
  max_policy_age: ${off_by_n}
  dp_size: 1

ref_model:
  model:
    name: qwen3
    flavor: 8B
    hf_assets_path: hf://${model}
  training:
    seq_len: ${trainer.training.seq_len}
    dtype: bfloat16
    gc_freq: 1
  compile:
    enable: ${compile}
  parallelism:
    data_parallel_replicate_degree: 1
    data_parallel_shard_degree: 1
    tensor_parallel_degree: 4
    pipeline_parallel_degree: 1
    context_parallel_degree: 1
    expert_parallel_degree: 1
  checkpoint:
    initial_load_path: hf://${model}
    initial_load_in_hf: true
  comm:
    init_timeout_seconds: 1800

services:
  generator:
    procs: 4
    num_replicas: 1
    hosts: 1
    with_gpus: true
    mesh_name: generator
  ref_model:
    procs: 4
    num_replicas: 1
    hosts: 1
    with_gpus: true
    mesh_name: ref_model
  reward_actor:
    procs: 1
    num_replicas: 1
    with_gpus: false
    mesh_name: reward_actor

actors:
  dataset:
    procs: 1
    with_gpus: false
    mesh_name: dataset
  trainer:
    procs: 4
    hosts: 1
    with_gpus: true
    mesh_name: trainer
  replay_buffer:
    procs: 1
    with_gpus: false
    mesh_name: replay_buffer
  compute_advantages:
    procs: 1
    with_gpus: false
    mesh_name: compute_advantages