# DDP 16, no FSDP, lbs=4, selective recomputation -> ~55216MiB / 65536MiB VRAM in use

comm:
  trace_buf_size: 0
  init_timeout_seconds: 1800

model_name: "Qwen/Qwen3-1.7B"

model:
  name: qwen3
  flavor: 1.7B
  hf_assets_path: hf://${model_name}

provisioner:
  launcher: slurm
  job_name: sft_qwen3_1.7b
  slurm_args:
    account: AIFAC_L07_016
    qos: qos_llm_min
    partition: boost_usr_prod
    nodes: 4
    export: ALL,PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    exclude: lrdn[1831-3456]
    error: "/leonardo_scratch/fast/iGen_train/dsalvati/forge/logs/dp16/%x_%j.err"
    output: "/leonardo_scratch/fast/iGen_train/dsalvati/forge/logs/dp16/%x_%j.out"
  mem: 0
  cpus_per_task: 32
  gpus_per_node: 4

optimizer:
  name: AdamW
  lr: 1e-5
  eps: 1e-8

lr_scheduler:
  warmup_steps: 200

training:
  local_batch_size: 4
  seq_len: 4096
  max_norm: 1.0
  steps: 1000
  compile: false
  dtype: bfloat16
  gc_freq: 1
  dataset:
    - path: "/leonardo_scratch/fast/iGen_train/datasets/ultrachat_200k"
      split: "train_sft[:95%]"

eval:
  eval_every_n_steps: 1000
  max_eval_steps: null
  dataset:
    - path: "/leonardo_scratch/fast/iGen_train/datasets/ultrachat_200k"
      split: "train_sft[95%:]"

parallelism:
  data_parallel_replicate_degree: 16
  data_parallel_shard_degree: 1
  tensor_parallel_degree: 1
  pipeline_parallel_degree: 1
  context_parallel_degree: 1
  expert_parallel_degree: 1
  disable_loss_parallel: false

checkpoint:
  enable: true
  folder: ./checkpoint
  initial_load_path: hf://${model_name}
  initial_load_in_hf: true
  last_save_in_hf: false
  last_save_model_only: false
  interval: 50
  async_mode: "disabled"

activation_checkpoint:
  mode: selective
  selective_ac_option: op

metric_logging:
  wandb:
    project: sft-training
    group: sft_exp_${oc.env:USER}
    logging_mode: global_reduce
  console:
    logging_mode: global_reduce


services: {}

actors:
  sft_trainer:
    procs: 4
    hosts: 4
    with_gpus: true
    mesh_name: sft_trainer